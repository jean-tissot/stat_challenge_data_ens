{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-ZJefpAeH1qX"
   },
   "outputs": [],
   "source": [
    "import h5py,pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquisition des données pour utilisation dans Jupyter (local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_S-W18PtH697"
   },
   "outputs": [],
   "source": [
    "def dataread():\n",
    "    X_file=h5py.File(\"C:/Users/AntoineLespinasse/Desktop/STATS/Projet/data/X_train_new.h5\",'r') # X est ici au format \"HDF5 dataset\"\n",
    "    X=np.array(X_file['features']) # X est ici au format \"ndarray\"\n",
    "    \n",
    "    X_final_file=h5py.File(\"C:/Users/AntoineLespinasse/Desktop/STATS/Projet/data/X_test_new.h5\",'r') # X_final est ici au format \"HDF5 dataset\"\n",
    "    X_final=np.array(X_final_file['features']) # X_final est ici au \"ndarray\"\n",
    "\n",
    "    y=pd.read_csv(\"C:/Users/AntoineLespinasse/Desktop/STATS/Projet/data/y_train_AvCsavx.csv\") # y est ici au format \"pandas DataFrame\"\n",
    "    y=np.array(y['label']) # y est ici au format \"ndarray\"\n",
    "\n",
    "    return X, y, X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquisition des données pour utilisation dans Collab (cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def dataread():\n",
    "    X_file=h5py.File(\"drive/MyDrive/X_train_new.h5\",'r') # X est ici au format \"HDF5 dataset\"\n",
    "    X=np.array(X_file['features']) # X est ici au format \"ndarray\"\n",
    "    \n",
    "    X_final_file=h5py.File(\"drive/MyDrive/X_test_new.h5\",'r') # X_final est ici au format \"HDF5 dataset\"\n",
    "    X_final=np.array(X_final_file['features']) # X_final est ici au \"ndarray\"\n",
    "\n",
    "    y=pd.read_csv(\"drive/MyDrive/y_train_AvCsavx.csv\") # y est ici au format \"pandas DataFrame\"\n",
    "    y=np.array(y['label']) # y est ici au format \"ndarray\"\n",
    "\n",
    "    return X, y, X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OdIaWy5fH8sK"
   },
   "outputs": [],
   "source": [
    "def datatreat_1(X0, y0):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in range(np.shape(X0)[0]):\n",
    "        for j in range(np.shape(X0)[1]):\n",
    "            X.append(X0[i,j,:,:])\n",
    "            y.append(y0[i])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.6, shuffle=True)\n",
    "\n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jwBMrdSsIEeL"
   },
   "outputs": [],
   "source": [
    "def cnn_1():\n",
    "  model = keras.Sequential(\n",
    "    [\n",
    "      layers.Conv2D(100, (3,3), padding='same', activation='relu', input_shape=(7,500,1)),\n",
    "      layers.MaxPool2D((2,2), padding='same'),\n",
    "      layers.Conv2D(100, (3,3), padding='same', activation='relu'),\n",
    "      layers.MaxPool2D((2,2), padding='same'),\n",
    "      layers.Conv2D(300, (2,3), padding='same', activation='relu'),\n",
    "      layers.MaxPool2D((2,2), padding='same'),\n",
    "      layers.Conv2D(400, (1,7), padding='same', activation='relu'),\n",
    "      layers.MaxPool2D((1,2), padding='same'),\n",
    "      layers.Conv2D(100, (1,3), padding='same', activation='relu'),\n",
    "      layers.Conv2D(100, (1,3), padding='same', activation='relu'),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(50, activation='relu'),\n",
    "      layers.Dense(1, activation='sigmoid')\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4r-cpi1Nxk5",
    "outputId": "a3b21eed-a8f9-4340-f9fc-5dbc5f42220c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22704, 7, 500, 1)\n",
      "(15136, 7, 500, 1)\n",
      "(22704,)\n",
      "(15136,)\n"
     ]
    }
   ],
   "source": [
    "X, y, X_final = dataread()\n",
    "\n",
    "X_train, X_test, y_train, y_test = datatreat_1(X, y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 7, 500, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 7, 500, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KT_OABHHIPN6",
    "outputId": "4f88ca43-faa2-465c-a9ef-2a28f220223d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 7, 500, 100)       1000      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 250, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 250, 100)       90100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 125, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 125, 300)       180300    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 63, 300)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 63, 400)        840400    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 32, 400)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 32, 100)        120100    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 32, 100)        30100     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                160050    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,422,101\n",
      "Trainable params: 1,422,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "355/355 [==============================] - 21s 52ms/step - loss: 0.9798 - accuracy: 0.7454\n",
      "Epoch 2/6\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 0.5478 - accuracy: 0.7753\n",
      "Epoch 3/6\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 0.5258 - accuracy: 0.7831\n",
      "Epoch 4/6\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 0.5306 - accuracy: 0.7780\n",
      "Epoch 5/6\n",
      "355/355 [==============================] - 18s 50ms/step - loss: 0.5282 - accuracy: 0.7801\n",
      "Epoch 6/6\n",
      "355/355 [==============================] - 18s 51ms/step - loss: 0.5339 - accuracy: 0.7733\n",
      "Evaluate on test data\n",
      "473/473 [==============================] - 6s 11ms/step - loss: 0.5284 - accuracy: 0.7814\n",
      "test loss, test acc: [0.5283670425415039, 0.781382143497467]\n"
     ]
    }
   ],
   "source": [
    "benchmark = cnn_1()\n",
    "\n",
    "print(benchmark.summary())\n",
    "\n",
    "benchmark.fit(X_train, y_train, epochs=6, batch_size=64)\n",
    "\n",
    "print(\"Evaluate on test data\")\n",
    "results = benchmark.evaluate(X_test, y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
